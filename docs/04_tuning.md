# 実際にチューニングをしてみよう

## ルール

みなさんがデプロイした本番環境のロードバランサに対して、常時リクエストが送られ続けます。
また、このリクエストは時間に応じて、単位時間あたりのリクエストがどんどん増えていきます。

スコア計算は、以下の 2 つを指標として行われます。

- ベンチマーカーからのリクエストに 2xx を返した数
- ベンチマーカーからのリクエストの単位時間あたりの平均レスポンスタイム
  - 実際のスコアは、平均レスポンスタイムに一定の値を乗算した値が用いられます

ベンチマーカーは特定の定数を投稿し、その値を取得するような挙動もしますが、ベンチマーカー側の定数が書き換わっても正しく動作するようにしてください。
ベンチマーカーが投稿したデータは次のリクエストで取得できる必要がありますが、ベンチマーカーが投稿したデータ以外のデータは一定時間後に正しい数値に反映されていれば問題ないものとします。

## チューニングポイント

まずは今日説明した、以下の 2 つを行うことを目指しましょう。

- インデックスの貼られていないテーブルに適切なインデックスを貼る
- N+1 クエリが発生している箇所を解消する

余裕のある方は、次のようなチューニングポイントも探して解消してみましょう。

- N+1 リクエストの解消
- インデックスでは解決できない重たいクエリ

それぞれ簡単に方針を示します。

### N+1 リクエストの解消

N+1 クエリと同様に、特定のサービス A からリストを取得し、そのリストを元にして別のサービス B に対してリクエストを発行したい場合があります。
こういったケースでは、N+1 クエリと同様に、取得したリストの件数分だけ別のサービスにリクエストを発行する必要が発生してしまい、重篤なパフォーマンス劣化を引き起こす可能性があります。

N+1 リクエストを解決するために、N+1 クエリと同様の戦略を取ることができます。
例えば、`id` の配列 `ids` を受け取り、`Recipe` のリストを返す `BatchGetRecipes` を実装することを考えます。

```protobuf
message BatchGetRecipesRequest {
    repeated uint64 recipe_ids = 1;
}

message BatchGetRecipesResponse {
    repeated main.resources.v1.Recipe recipes = 1;
}
```

アプリケーション側では例えば次のように実装します。

```ruby
def batch_get_recipes(request, call)
  # TODO: Avoid to N+1 query
  recipes = request.ids.any? ? Recipe.where(id: request.ids.to_a) : Recipe.none

  Main::Services::V1::BatchGetRecipesResponse.new(
    recipes: recipes.map(&:as_protocol_buffer)
  )
end
```

リクエスタは、サービス A から取得したリストから `ids` を生成し、次のようにリクエストを行います。

```ruby
  ids = response.map(&:id)
  request = Main::Services::V1::BatchGetRecipesRequest.new(
    ids: ids,
  )
```

このようにすることで、リストの件数が 10 件だった場合 11 回リクエストが行われていたものが、
2 回のリクエストでデータを取得できるようにすることが可能になっています。

### インデックスでは解決できない重たいクエリ

複雑なクエリや、仕様上どうしても大量のデータを扱わなければならないクエリはどうしても存在するものです。
そういったケースでは、反映をバッチで行ったり、キャッシュを行うことで対処することがあります。

もちろん仕様やユーザの要求に応じてになりますが、結果整合性が満たせれば十分で即時反映ではなくて良いケース、
一定時間後に正しい値が表示されれば良いケースなど、妥協案を見つけることも重要です。

例えばバッチで 1 日 1 回の更新にしたり、ジョブキューを使って少しの遅延で反映させるようにしたり、アプリケーション側でのキャッシュ (refs: https://railsguides.jp/caching_with_rails.html) などを利用するなどの選択肢があります。
